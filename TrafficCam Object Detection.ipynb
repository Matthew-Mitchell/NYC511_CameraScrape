{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a17c0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be138fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade -q git+https://github.com/keras-team/keras-cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e60b4",
   "metadata": {},
   "source": [
    "## Reference List\n",
    "\n",
    "https://developer.nvidia.com/blog/fast-track-your-production-ai-with-pre-trained-models-and-tao-toolkit-3-0/\n",
    "https://keras.io/examples/timeseries/timeseries_traffic_forecasting/\n",
    "https://keras.io/guides/keras_cv/object_detection_keras_cv/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b057a700",
   "metadata": {},
   "source": [
    "## GPU Checks\n",
    "https://stackoverflow.com/questions/44544766/how-do-i-check-if-keras-is-using-gpu-version-of-tensorflow#44547144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babfb131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 18:37:31.342365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 18:37:32.213039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/matt/miniconda3/envs/robots/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 18:37:33.207474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 18:37:33.331122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 18:37:33.331614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f008c68",
   "metadata": {},
   "source": [
    "## Previous TensorFlow Install Guide\n",
    "https://www.tensorflow.org/install/pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb7ed6c",
   "metadata": {},
   "source": [
    "https://keras.io/examples/vision/yolov8/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a6934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf35829",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3cbf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 5\n",
    "GLOBAL_CLIPNORM = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5782e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"CfThL4bE8Z\")\n",
    "# project = rf.workspace(\"roboflow-gw7yv\").project(\"self-driving-car\")\n",
    "# dataset = project.version(3).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e50790",
   "metadata": {},
   "source": [
    "## Get Input Images and Annotations for the Yolo8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d877e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    \"car\",\n",
    "    \"pedestrian\",\n",
    "    \"trafficLight\",\n",
    "    \"biker\",\n",
    "    \"truck\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "# Path to images and annotations\n",
    "path_images = \"export/images/\" #\"/kaggle/input/dataset/data/images/\"\n",
    "path_annot = \"export/labels/\" #\"/kaggle/input/dataset/data/annotations/\"\n",
    "\n",
    "# Get all XML file paths in path_annot and sort them\n",
    "txt_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_annot, file_name)\n",
    "        for file_name in os.listdir(path_annot)\n",
    "        if file_name.endswith(\".txt\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_images, file_name)\n",
    "        for file_name in os.listdir(path_images)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "676770cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['export/labels/1478896928938416423_jpg.rf.kYj91j6BMt3KIYihOFLT.txt',\n",
       " 'export/labels/1478900095024715037_jpg.rf.bf962ff644f95d0c82417d01eceecb86.txt',\n",
       " 'export/labels/1478899896786707985_jpg.rf.RkD49wNL5ucdyWvu3aqY.txt',\n",
       " 'export/labels/1478020604203617302_jpg.rf.ed3d14d0eff881495e9d584862382013.txt',\n",
       " 'export/labels/1478896849527318206_jpg.rf.3e946a060fbf6c6b9bc5d1b288026436.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_files = glob.glob(f\"{path_annot}*\")\n",
    "print(len(label_files))\n",
    "label_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b0f2a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Annotated (xml) files: 29,800\n",
      "Number of Image (jpg) files: 29,800\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number Annotated (xml) files: {len(txt_files):,}\")\n",
    "print(f\"Number of Image (jpg) files: {len(jpg_files):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49de4c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['export/images/1478019952686311006_jpg.rf.54e2d12dbabc46be3c78995b6eaf3fee.jpg',\n",
       " 'export/images/1478019952686311006_jpg.rf.JLSB3LP2Q4RuGHYKqfF6.jpg',\n",
       " 'export/images/1478019953180167674_jpg.rf.8a816c9d7e9b423a63ed6ecd4a663e47.jpg',\n",
       " 'export/images/1478019953180167674_jpg.rf.azslsZnM8FLQPu3QWLTl.jpg',\n",
       " 'export/images/1478019953689774621_jpg.rf.2e4b7ae29c3379da1282e85cff4c1745.jpg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpg_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "068d9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70a0e134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['export/images/1478899691122801774_jpg.rf.721a2baae483c8999be1c2303d3bfc55.jpg']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding a Files Pair....\n",
    "txt_file = np.random.choice(txt_files)\n",
    "jpg_pair = txt_file.replace(\".txt\",\".jpg\").replace('/labels/','/images/')\n",
    "[f for f in jpg_files if f == jpg_pair]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4281dc",
   "metadata": {},
   "source": [
    "## Preview an Annotation File\n",
    "\n",
    "> My Download from RoboFlow: https://public.roboflow.com/object-detection/self-driving-car/3#\n",
    "produced txt files instead of XML files. Adapting code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7410978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 0.43359375 0.48828125 0.0166015625 0.0283203125\n",
      "1.0 0.458984375 0.494140625 0.0244140625 0.0263671875\n",
      "1.0 0.5087890625 0.4970703125 0.0283203125 0.0380859375\n",
      "2.0 0.9287109375 0.5107421875 0.0361328125 0.21875\n"
     ]
    }
   ],
   "source": [
    "txt_file = txt_files[0]\n",
    "with open(txt_file, \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        class_, xmin, xmax, ymin, ymax = [float(x) for x in line.split()]\n",
    "        print(class_, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc5c97",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "> Appears to be of the form:  \n",
    "category, bounding box x?min x?max y?min y?max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b762b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(txt_file):\n",
    "    jpg_pair = txt_file.replace(\".txt\",\".jpg\").replace('/labels/','/images/')\n",
    "    classes = []\n",
    "    boxes = []\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            cls, xmin, xmax, ymin, ymax = [float(x) for x in line.split()]\n",
    "            cls = int(cls)\n",
    "            classes.append(cls)\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "    return jpg_pair, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6703bc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ef3606ae7c4961a925c03eeb56f501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image paths: 29,800\n"
     ]
    }
   ],
   "source": [
    "# def parse_annotation(xml_file):\n",
    "#     tree = ET.parse(xml_file)\n",
    "#     root = tree.getroot()\n",
    "\n",
    "#     image_name = root.find(\"filename\").text\n",
    "#     image_path = os.path.join(path_images, image_name)\n",
    "\n",
    "#     boxes = []\n",
    "#     classes = []\n",
    "#     for obj in root.iter(\"object\"):\n",
    "#         cls = obj.find(\"name\").text\n",
    "#         classes.append(cls)\n",
    "\n",
    "#         bbox = obj.find(\"bndbox\")\n",
    "#         xmin = float(bbox.find(\"xmin\").text)\n",
    "#         ymin = float(bbox.find(\"ymin\").text)\n",
    "#         xmax = float(bbox.find(\"xmax\").text)\n",
    "#         ymax = float(bbox.find(\"ymax\").text)\n",
    "#         boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "#     class_ids = [\n",
    "#         list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n",
    "#         for cls in classes\n",
    "#     ]\n",
    "#     return image_path, boxes, class_ids\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "bbox = []\n",
    "classes = []\n",
    "for txt_file in tqdm(txt_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(txt_file)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)\n",
    "print(f\"Number of image paths: {len(image_paths):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e43a9",
   "metadata": {},
   "source": [
    "Here we are using tf.ragged.constant to create ragged tensors from the bbox and classes lists. A ragged tensor is a type of tensor that can handle varying lengths of data along one or more dimensions. This is useful when dealing with data that has variable-length sequences, such as text or time series data.\n",
    "\n",
    "```python\n",
    "classes = [\n",
    "    [8, 8, 8, 8, 8],      # 5 classes\n",
    "    [12, 14, 14, 14],     # 4 classes\n",
    "    [1],                  # 1 class\n",
    "    [7, 7],               # 2 classes\n",
    " ...]\n",
    "\n",
    "bbox = [\n",
    "    [[199.0, 19.0, 390.0, 401.0],\n",
    "    [217.0, 15.0, 270.0, 157.0],\n",
    "    [393.0, 18.0, 432.0, 162.0],\n",
    "    [1.0, 15.0, 226.0, 276.0],\n",
    "    [19.0, 95.0, 458.0, 443.0]],     #image 1 has 4 objects\n",
    "    [[52.0, 117.0, 109.0, 177.0]],   #image 2 has 1 object\n",
    "    [[88.0, 87.0, 235.0, 322.0],\n",
    "    [113.0, 117.0, 218.0, 471.0]],   #image 3 has 2 objects\n",
    " ...]\n",
    "```\n",
    "\n",
    "In this case, the bbox and classes lists have different lengths for each image, depending on the number of objects in the image and the corresponding bounding boxes and classes. To handle this variability, ragged tensors are used instead of regular tensors.\n",
    "\n",
    "Later, these ragged tensors are used to create a tf.data.Dataset using the from_tensor_slices method. This method creates a dataset from the input tensors by slicing them along the first dimension. By using ragged tensors, the dataset can handle varying lengths of data for each image and provide a flexible input pipeline for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77b880ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 20:47:19.429457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 20:47:19.430048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 20:47:19.430370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 20:47:20.330626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 20:47:20.331056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 20:47:20.331376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 20:47:20.331675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4762 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "bbox = tf.ragged.constant(bbox)\n",
    "classes = tf.ragged.constant(classes)\n",
    "image_paths = tf.ragged.constant(image_paths)\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915589fe",
   "metadata": {},
   "source": [
    "### Split INto Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21f5b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of validation samples\n",
    "num_val = int(len(xml_files) * SPLIT_RATIO)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "val_data = data.take(num_val)\n",
    "train_data = data.skip(num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588338f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
